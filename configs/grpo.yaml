# GRPO (Group Relative Policy Optimization) Configuration
# -------------------------------------------------------

model:
  # Qwen2.5-3B-Instruct model
  name: "Qwen/Qwen2.5-3B-Instruct"
  # GPU selection (sets CUDA_VISIBLE_DEVICES before importing torch):
  #   - "auto": use all available GPUs (default)
  #   - "cuda:0": use only GPU 0
  #   - "cuda:2": use only GPU 2
  #   - [2, 7]: use GPUs 2 and 7 for model parallelism
  device: [3, 5]

training:
  max_train_samples: 500  # null = use all; set integer to limit
  num_epochs: 1
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 4
  learning_rate: 5.0e-6
  weight_decay: 0.01
  warmup_ratio: 0.1
  lr_scheduler_type: "cosine"
  bf16: true
  logging_steps: 10
  save_strategy: "epoch"
  seed: 42
  gradient_checkpointing: true

grpo:
  num_generations: 8
  max_new_tokens: 1024       # max tokens the model can generate per completion
  temperature: 0.7
  beta: 0  # KL penalty coefficient, try 0 too
